{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mary/miniconda3/envs/robustbench/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "import enumeration\n",
    "import utils_func\n",
    "import argparse\n",
    "import torch\n",
    "import gc\n",
    "\n",
    "from torchvision.transforms import transforms\n",
    "\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_names_dict = {\n",
    "    \"trades\": \"Zhang2019Theoretically\",\n",
    "    \"mart\": \"Wang2020Improving\",\n",
    "    \"wang2023\": \"Wang2023Better_WRN-28-10\",\n",
    "    'SAT' : 'Engstrom2019Robustness',\n",
    "    'wu2020' : 'Wu2020Adversarial',\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--threat model'], dest='threat model', nargs=None, const=None, default='Linf', type=<class 'str'>, choices=['Linf', 'L2'], required=False, help='threat model', metavar=None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parse arguments\n",
    "parser = argparse.ArgumentParser(description=\"Process some parameters.\")\n",
    "parser.add_argument(\"--wandb_logging\", type=bool, default=False, help=\"log to wandb\")\n",
    "parser.add_argument(\"--batch_size\", type=int, default=64, help=\"batch size\")\n",
    "parser.add_argument(\n",
    "    \"--dataset\",\n",
    "    type=str,\n",
    "    default=\"cifar10\",\n",
    "    choices=[\"cifar10\", \"cifar100\"],\n",
    "    help=\"dataset\",\n",
    ")\n",
    "parser.add_argument(\"--epsilon\", type=float, default=8 / 255, help=\"epsilon\")\n",
    "parser.add_argument(\"--alpha\", type=float, default=2 / 255, help=\"alpha\")\n",
    "parser.add_argument(\n",
    "    \"--sampling_iterations\", type=int, default=20, help=\"sampling iterations\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--architecture_name\", type=str, default=\"WideResNet\", help=\"architecture name\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--from_robustbench\", type=bool, default=True, help=\"load model from robustbench\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--init\",\n",
    "    type=str,\n",
    "    default=\"random\",\n",
    "    choices=[\"random\", \"pca\", \"gaussian\", \"informative\", \"informative+pca\"],\n",
    "    help=\"initialization for the generation\",\n",
    ")\n",
    "\n",
    "parser.add_argument(\"--seed\", type=int, default=0, help=\"random seed\")\n",
    "parser.add_argument(\"--data_dir\", type=str, default=\"./data\", help=\"data directory\")\n",
    "parser.add_argument(\n",
    "    \"--model_name\",\n",
    "    type=str,\n",
    "    default=\"Zhang2019Theoretically\",\n",
    "    choices=[model_names_dict.keys()],\n",
    "    help=\"define the name of the model to be loaded\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--model_source\",\n",
    "    type=str,\n",
    "    default=\"robustbench\",\n",
    "    choices=[\"robustbench\", \"jem\", \"local\"],\n",
    "    help=\"the source from where the model is loaded\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--model_dir\",\n",
    "    type=str,\n",
    "    default=\"./models\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--threat model\",\n",
    "    type=str,\n",
    "    default=\"Linf\",\n",
    "    choices=[\"Linf\", \"L2\"],\n",
    "    help=\"threat model\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using default arguments\n"
     ]
    }
   ],
   "source": [
    "\n",
    "try:\n",
    "    args = parser.parse_args()\n",
    "    wandb = args.wandb_logging\n",
    "    batch_size = args.batch_size\n",
    "    dataset = args.dataset\n",
    "    epsilon = args.epsilon\n",
    "    alpha = args.alpha\n",
    "    sampling_iterations = args.sampling_iterations\n",
    "    architecture_name = args.architecture_name\n",
    "    from_robustbench = args.from_robustbench\n",
    "    initialization = args.init\n",
    "    data_dir = args.data_dir\n",
    "    seed = args.seed\n",
    "    model_name = args.model_name\n",
    "    model_source = args.model_source\n",
    "    model_dir = args.model_dir\n",
    "    threat_model = args.threat_model\n",
    "\n",
    "    print(\"Using arguments from parser\")\n",
    "\n",
    "except:\n",
    "    print(\"Using default arguments\")\n",
    "    wandb = False\n",
    "    batch_size = 64\n",
    "    dataset = \"cifar10\"\n",
    "    epsilon = 8 / 255\n",
    "    alpha = 2 / 255\n",
    "    sampling_iterations = 20\n",
    "    architecture_name = \"WideResNet\"\n",
    "    from_robustbench = True\n",
    "    init = \"random\"\n",
    "    data_dir = \"./data\"\n",
    "    seed = 0\n",
    "    model_name = \"Wang2020Improving\"\n",
    "    source = 'robustbench'\n",
    "    model_dir = \"./models\"\n",
    "    threat_model = \"Linf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed for the reproducibility of the results\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from utils import fix_seed\n",
    "\n",
    "fix_seed(seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logging on wandb\n",
    "if wandb:\n",
    "    import wandb\n",
    "\n",
    "    config = {\n",
    "        \"dataset\": dataset,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"epsilon\": epsilon,\n",
    "        \"alpha\": alpha,\n",
    "        \"sampling_iterations\": sampling_iterations,\n",
    "        \"architecture name\": architecture_name,\n",
    "        \"from_robustbench\": from_robustbench,\n",
    "        \"initialization\": init,\n",
    "        'model name': model_name,\n",
    "        'model source': model_source\n",
    "    }\n",
    "    wandb.init(name=\"generation\", project=\"LE-PGD\",\n",
    "               entity=\"le-pgd\", config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "dataset_train, dataset_test = utils.load_clean_dataset(\n",
    "    dataset=enumeration.BenchmarkDataset(dataset.lower()),\n",
    "    n_examples=None,\n",
    "    data_dir=data_dir,\n",
    "    transform=transform,\n",
    ")\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    dataset_train, batch_size=batch_size, shuffle=True\n",
    ")\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    dataset_test, batch_size=batch_size, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define and load the model\n",
    "\n",
    "The default option is to load the model whose name is specified in the arguments "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from robustbench.utils import load_model\n",
    "from torch import nn\n",
    "\n",
    "from JEMPP.models.jem_models import F, CCF\n",
    "from JEMPP.models.wideresnet import Wide_ResNet as WideResNet\n",
    "\n",
    "\n",
    "architecture_dict = {'wideresnet': WideResNet}\n",
    "\n",
    "assert architecture_name.lower() in architecture_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the model to load "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "for m_name in model_names_dict.keys():\n",
    "    models[m_name] = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trades loaded\n",
      "Model mart loaded\n",
      "Model wang2023 loaded\n",
      "Model SAT loaded\n",
      "Model wu2020 loaded\n"
     ]
    }
   ],
   "source": [
    "for i, model_name_i in enumerate(model_names_dict.keys()):\n",
    "    \n",
    "    if model_source == \"robustbench\":\n",
    "        model = load_model(\n",
    "            model_name=model_names_dict[model_name_i],\n",
    "            dataset=dataset,\n",
    "            threat_model=threat_model,\n",
    "            model_dir=\"./models\",\n",
    "        )\n",
    "        model = nn.DataParallel(model, device_ids=[0])\n",
    "        model.to(device)\n",
    "    elif model_source == \"jem\":\n",
    "        model_cls = F\n",
    "        model = model_cls(\n",
    "            enumeration.dataset_image_size[dataset],\n",
    "            enumeration.dataset_num_classes[dataset],\n",
    "            norm=\"batch\",\n",
    "            n_classes=enumeration.dataset_num_classes[dataset],\n",
    "            model=\"wrn\",\n",
    "        )\n",
    "        ckpt_dict = torch.load(\"./models/cifar10/Linf/sadajem5_95.5_9.4.pt\")\n",
    "        model.load_state_dict(ckpt_dict[\"model_state_dict\"])\n",
    "        model = nn.DataParallel(model, device_ids=[0, 1])\n",
    "        model.to(device)\n",
    "        replay_buffer = ckpt_dict[\"replay_buffer\"]\n",
    "\n",
    "    elif model_source == \"local\":\n",
    "        model_path = model_dir + \"/wandb_model/\" + model_name + \".pt\"\n",
    "        # check missimg 2 factors in architecture instanciation\n",
    "        model = (\n",
    "            architecture_dict[architecture_name]()\n",
    "            .to(device)\n",
    "            .load_state_dict(torch.load(model_path))\n",
    "            .eval()\n",
    "        )\n",
    "    \n",
    "    models[model_name_i]=model.module\n",
    "    del model\n",
    "    print(f\"Model {model_name_i} loaded\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below there is the computation of the mean of the dataset for each category and then the estimate of the dataset as a GMM where each class is a gaussian distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Mean and Covariance Already Computed, skipping\n"
     ]
    }
   ],
   "source": [
    "utils_func.category_mean(\n",
    "    dload_train=train_dataloader,\n",
    "    n_classes=enumeration.dataset_num_classes[dataset],\n",
    "    name_dataset=dataset,\n",
    "    image_size=enumeration.dataset_image_size[dataset],\n",
    "    n_channels=3,\n",
    "    data_dir=data_dir,\n",
    ")\n",
    "buffer = utils.center_initialization(\n",
    "    dataset=dataset, n_classes=enumeration.dataset_num_classes[dataset]\n",
    ")\n",
    "\n",
    "replay_buffer = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of the performance of the model for each initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The evaluation focuses on establishing the best way of initializing the generation.\n",
    "The fixed parameters are :\n",
    "- generated samples : 12 per class\n",
    "- labels to generate : a subset of 10 labels \n",
    "- seed: defined as argument \n",
    "- the norm considered in the perturbation: Linf \n",
    "- Loss for the perturbation : energy_xy\n",
    "- Dataset\n",
    "- optimizer: SGLD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In eacho of these plots the images show for each initialization method images generated for 5 classes.\n",
    "The first line is generated with TRADES -\n",
    "The second line is generated with MART -\n",
    "The third line is Wang2023 model, trained on DM generated images https://arxiv.org/pdf/2302.04638.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 1, 2, 3, 4], [5, 6, 7, 8, 9]]\n"
     ]
    }
   ],
   "source": [
    "num_samples = 5\n",
    "label_to_plot = [i for i in range(10)]\n",
    "label_to_plot = [[i for i in label_to_plot[:len(label_to_plot) // 2]], [i for i in label_to_plot[len(label_to_plot) // 2:]]]\n",
    "print(label_to_plot)\n",
    "loss = 'energy_xy'\n",
    "step_size = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The start is ```informative```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trades\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mary/miniconda3/envs/robustbench/lib/python3.10/site-packages/torch/nn/modules/conv.py:456: UserWarning: Applied workaround for CuDNN issue, install nvrtc.so (Triggered internally at /opt/conda/conda-bld/pytorch_1695392020201/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:80.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(name)\n\u001b[1;32m      6\u001b[0m fix_seed(seed\u001b[38;5;241m=\u001b[39mseed)\n\u001b[0;32m----> 7\u001b[0m x0, imgs \u001b[38;5;241m=\u001b[39m \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnew_samples\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstep_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstep_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43minizialization\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minformative\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_steps_sampling\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreplay_buffer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreplay_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbuffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m init\u001b[38;5;241m.\u001b[39mappend(x0)\n\u001b[1;32m     20\u001b[0m img\u001b[38;5;241m.\u001b[39mappend(imgs)\n",
      "File \u001b[0;32m/media/mary/T7/code/LE_PGD/ablation/utils.py:798\u001b[0m, in \u001b[0;36mnew_samples\u001b[0;34m(model, label, batch_size, step_size, n_steps, inizialization, n_steps_sampling, loss, algo, replay_buffer, buffer, dataset, **kwargs)\u001b[0m\n\u001b[1;32m    795\u001b[0m     X0\u001b[38;5;241m.\u001b[39mappend(x0)\n\u001b[1;32m    796\u001b[0m     samples\u001b[38;5;241m.\u001b[39mappend(final_samples)\n\u001b[0;32m--> 798\u001b[0m     \u001b[43mgc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    799\u001b[0m     torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n\u001b[1;32m    801\u001b[0m \u001b[38;5;66;03m# concatante the list of tensors to a single tensor\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for labels in label_to_plot:\n",
    "    init, img = [], []\n",
    "    for name, model in models.items():\n",
    "        print(name)\n",
    "\n",
    "        fix_seed(seed=seed)\n",
    "        x0, imgs = utils.new_samples(\n",
    "            model=model,\n",
    "            label=labels,\n",
    "            batch_size=num_samples,\n",
    "            step_size=step_size,\n",
    "            n_steps=50,\n",
    "            inizialization=\"informative\",\n",
    "            n_steps_sampling=1,\n",
    "            loss=loss,\n",
    "            replay_buffer=replay_buffer,\n",
    "            buffer=buffer,\n",
    "        )\n",
    "        init.append(x0)\n",
    "        img.append(imgs)\n",
    "\n",
    "    init_cat = torch.cat(init, dim=0)\n",
    "    img_cat = torch.cat(img, dim=0)\n",
    "    \n",
    "    utils_func.plot_imgs_generated(\n",
    "        init_cat,\n",
    "        inizialization=\"informative\",\n",
    "        rows= len(model_names_dict.keys()),\n",
    "        size=(40, 10),\n",
    "        path=\"./data/imgs_x0.pdf\",\n",
    "        name=\"imgs_x0: \",\n",
    "    )\n",
    "    utils_func.plot_imgs_generated(\n",
    "        img_cat,\n",
    "        inizialization=\"informative\",\n",
    "        rows=len(model_names_dict.keys()),\n",
    "        size=(40, 10),\n",
    "        path=\"./data/imgs.pdf\",\n",
    "        name=\"imgs: \",\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The start is ```pca```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The retained variance is 0.95 and n_steps = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torchvision as tv\n",
    "\n",
    "def plot_imgs_generated(\n",
    "    imgs_generated,\n",
    "    inizialization,\n",
    "    rows=20,\n",
    "    size=(20, 30),\n",
    "    path=\"./data/imgs.pdf\",\n",
    "    name=\"test\",\n",
    "):\n",
    "\n",
    "    grid = tv.utils.make_grid(\n",
    "        imgs_generated.cpu(), nrow=imgs_generated.shape[0] // rows, normalize=True, \n",
    "    )\n",
    "    grid = grid.permute(1, 2, 0)\n",
    "    \n",
    "    dpi = plt.rcParams['figure.dpi'] #get the default dpi value\n",
    "    \n",
    "    fig_size = (size[0]/dpi*len(imgs_generated), size[1]/dpi)\n",
    "    # crete a row figure that subplots in it the images with a certain size\n",
    "    plt.\n",
    "    \n",
    "    plt.figure(figsize=fig_size)\n",
    "    \n",
    "    \n",
    "    # no border and no indexes on the axes\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "    plt.imshow(grid)\n",
    "\n",
    "    plt.savefig(path, format=\"pdf\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trades\n",
      "mart\n",
      "wang2023\n",
      "SAT\n",
      "wu2020\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAADMAAAAaCAYAAAAaAmTUAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAACQUlEQVR4nO3Xy4pdRRSA4X/VZZ8LrWLANg0BbYiOxAx9MgeOfBHBF/BBBMGJEQlEaURUkjQn3efsW1WttRzEB9iC4EH2P1zUoL6qSZW4u/M/KfzXG/g3WzHn2oo511bMubZizrW0dOGXX3zOu5eP+fnPWy4eXvMonjiVSuwGnv/0jF+e/8YHV5nPrj/l6cue/UVGA1w96Pn2u6c8fPwJ7+wqd3cz/etKqEcuHzzi5uYH4v49Pvr4Ca/uv+f68opfX93w47NbLt//kAB8/dU3i/a4/GZCYJ7uEWvsukSZejBl6gdabbS54uYMxwErE0FABFwLMTit1r9nQkoZ0wYITY0yz4g44k4SJcTMZtOx322Jsvy1tfhmurwhx0TqOsyM3XaH1kbs9qQUiTHQbbd0MZJTJKaEpMibp5+QciIEI8RAEMVU2e86cKfLmRSEYEYXE10WcCdKwMM/OO+lC00refsW5pGxKDFvcYnk7YaYEjFn3I3txQ7JG9QcU0PiBjUhxPRmZk5rlZgSqkqMkZQz6mAiFBVaLcyl0A8jzRZblmNqq5Qy0upMlyLD0KOqDKcTtVRaq9R5ZpoLpRRMG7UWBEPEaLWAO26GiyAhME4VgHkumDkeAs0bVYUYIhIF9eWaxZhSlePhD7z2dFK5P7xA5yOvbw+M/cDUj6g5L35/yXB3wE0xb5yOB4Ib06lHW0VVgcQ4TpTa6MeZ/nSkjAM6FaJOiGS2mw1vX+wJposxsv5nzrQVc66tmHNtxZxrK+Zc+wtl/TlgupfHcAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 40x10 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAADMAAAAaCAYAAAAaAmTUAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAACMklEQVR4nO3XS24UMRCA4b9ctns6IcnwGAWEWAASG8Th4AJcgTWX4DSw4CUBWSSQBGY0M93tJ1doJCRaqP+1F/WpvLCl1lr5TzL/eoC/2YyZajNmqs2YqTZjppode/D5i5ccnyz5fH7B8vQRt+2ePjhsveTL149sriLLE8uz0/t8/hWhtRj13Ftd8fHTB9o7Tzm0a9briI+CiTuOjh7w7ewtRW/x5PFDLt07Vn7Fj90FH95fcff0FNcqr1+9GTXj6M1YE6hxg62R1go27tEaGVKFXIi5R8WT9plQO5SMSAIyWiySEiKCAOgBgmK1koFYIkU8FIulgjicc9imQdGxI47HOKeIWeCco1BxTYuo4bB1WOvwanELwXtYWsVa8A4MFaOCeINYg6rSmEqfAguvaM54bfEWfKo0RvDWIBhssfg/eDmOvmYDjoVfkcqWEAzdwZIklSoZNZU2JRjA3GlI/YKUQY0FB73bUWrDAZBqoOsGbsgCCR0HptLpgq7rCcfQN4Eh9/R1IISBdDOOxozeTO63pBhJKVPVIMN3auqJQyFEy05aNknY7SGHDlN6So4Uo5Ro0NghpcdwjbWeQ5/YZ8+2VPrhJ845iImYCtJlFCE3icr41YzGlFLYbM7JecBLYrcNxNiz+XVN13fshx2GTLq6Jm8vKSVSykBc71Cx5BAoIVGjQyVwtk4oQsiFOGxJcSCmgguZgsNb5dh5CDIaI/N/ZqLNmKk2Y6bajJlqM2aq/QYYjxhiu9PmBwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 40x10 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trades\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(name)\n\u001b[1;32m      6\u001b[0m fix_seed(seed\u001b[38;5;241m=\u001b[39mseed)\n\u001b[0;32m----> 7\u001b[0m x0, imgs \u001b[38;5;241m=\u001b[39m \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnew_samples\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstep_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.8\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43minizialization\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpca\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_steps_sampling\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreplay_buffer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreplay_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbuffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvariance\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.95\u001b[39;49m\n\u001b[1;32m     20\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m init\u001b[38;5;241m.\u001b[39mappend(x0)\n\u001b[1;32m     22\u001b[0m img\u001b[38;5;241m.\u001b[39mappend(imgs)\n",
      "File \u001b[0;32m/media/mary/T7/code/LE_PGD/ablation/utils.py:763\u001b[0m, in \u001b[0;36mnew_samples\u001b[0;34m(model, label, batch_size, step_size, n_steps, inizialization, n_steps_sampling, loss, algo, replay_buffer, buffer, dataset, **kwargs)\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_steps_sampling):\n\u001b[1;32m    762\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m algo \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSGLD\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 763\u001b[0m         x0, final_samples, energy_dict \u001b[38;5;241m=\u001b[39m \u001b[43msample_q_SGLD\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    764\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    765\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreplay_buffer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreplay_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    766\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    767\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstep_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstep_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    768\u001b[0m \u001b[43m            \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    769\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    770\u001b[0m \u001b[43m            \u001b[49m\u001b[43minizialization\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minizialization\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    771\u001b[0m \u001b[43m            \u001b[49m\u001b[43mloss_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    772\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    773\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbuffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    774\u001b[0m \u001b[43m            \u001b[49m\u001b[43menergy_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menergy_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    775\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    776\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    777\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m algo \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHeun\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    778\u001b[0m         x0, final_samples \u001b[38;5;241m=\u001b[39m sample_q_Heun(\n\u001b[1;32m    779\u001b[0m             model,\n\u001b[1;32m    780\u001b[0m             replay_buffer\u001b[38;5;241m=\u001b[39mreplay_buffer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    790\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    791\u001b[0m         )\n",
      "File \u001b[0;32m/media/mary/T7/code/LE_PGD/ablation/utils.py:545\u001b[0m, in \u001b[0;36msample_q_SGLD\u001b[0;34m(model, replay_buffer, batch_size, step_size, y, n_steps, inizialization, loss_func, sigma_pca, mean_img, N_components, retained_variance, more_variance, dataset, buffer, energy_dict, **kwargs)\u001b[0m\n\u001b[1;32m    542\u001b[0m     adaptive \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    544\u001b[0m \u001b[38;5;66;03m# init the image X0 based on the MODE\u001b[39;00m\n\u001b[0;32m--> 545\u001b[0m x0, inds \u001b[38;5;241m=\u001b[39m \u001b[43mget_init_images\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    546\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreplay_buffer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreplay_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    547\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    548\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    549\u001b[0m \u001b[43m    \u001b[49m\u001b[43minizialization\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minizialization\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[43m    \u001b[49m\u001b[43msigma_pca\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msigma_pca\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmean_img\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmean_img\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    552\u001b[0m \u001b[43m    \u001b[49m\u001b[43mN_components\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mN_components\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    553\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretained_variance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretained_variance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    554\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmore_variance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmore_variance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    555\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    556\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbuffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    557\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    558\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    559\u001b[0m velocity \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros_like(x0)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    561\u001b[0m samples \u001b[38;5;241m=\u001b[39m x0\u001b[38;5;241m.\u001b[39mclone()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m/media/mary/T7/code/LE_PGD/ablation/utils.py:338\u001b[0m, in \u001b[0;36mget_init_images\u001b[0;34m(replay_buffer, batch_size, y, inizialization, sigma_pca, mean_img, N_components, retained_variance, more_variance, dataset, buffer, **kwargs)\u001b[0m\n\u001b[1;32m    335\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m    336\u001b[0m         sigma \u001b[38;5;241m=\u001b[39m sigma_pca\n\u001b[0;32m--> 338\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43minizializations\u001b[49m\u001b[43m[\u001b[49m\u001b[43minizialization\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    339\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimg_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./data/img_class_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.pt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    340\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_channels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimg_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_image_size\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmore_variance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmore_variance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[43m        \u001b[49m\u001b[43msigma_pca\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msigma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmean_img\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmean_img\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[43m        \u001b[49m\u001b[43mN_components\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mN_components\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretained_variance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretained_variance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgaussian_blur\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgaussian_blur\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    350\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret, []\n\u001b[1;32m    352\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m inizialization \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minformative+pca\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m/media/mary/T7/code/LE_PGD/ablation/utils_func.py:194\u001b[0m, in \u001b[0;36msample_x0_pca\u001b[0;34m(img_class, more_variance, img_size, n_channels, sigma_pca, mean_img, batch_size, N_components, retained_variance, gaussian_blur)\u001b[0m\n\u001b[1;32m    191\u001b[0m     img_class \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(list_of_tensors)\n\u001b[1;32m    193\u001b[0m pca \u001b[38;5;241m=\u001b[39m PCA(n_components\u001b[38;5;241m=\u001b[39mN_components)  \u001b[38;5;66;03m# (n_samples, n_features)\u001b[39;00m\n\u001b[0;32m--> 194\u001b[0m princ \u001b[38;5;241m=\u001b[39m \u001b[43mpca\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_class\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    196\u001b[0m mu_ \u001b[38;5;241m=\u001b[39m princ\u001b[38;5;241m.\u001b[39mmean_ \u001b[38;5;28;01mif\u001b[39;00m mean_img \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m img_class[mean_img]\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# else select the 10 less dominant just to see (assume PrinComp are sorted)\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/robustbench/lib/python3.10/site-packages/sklearn/base.py:1351\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1344\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1347\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1348\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1349\u001b[0m     )\n\u001b[1;32m   1350\u001b[0m ):\n\u001b[0;32m-> 1351\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/robustbench/lib/python3.10/site-packages/sklearn/decomposition/_pca.py:428\u001b[0m, in \u001b[0;36mPCA.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    411\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    412\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model with X.\u001b[39;00m\n\u001b[1;32m    413\u001b[0m \n\u001b[1;32m    414\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[38;5;124;03m        Returns the instance itself.\u001b[39;00m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 428\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    429\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/robustbench/lib/python3.10/site-packages/sklearn/decomposition/_pca.py:514\u001b[0m, in \u001b[0;36mPCA._fit\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;66;03m# Call different fits for either full or truncated SVD\u001b[39;00m\n\u001b[1;32m    513\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_svd_solver \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfull\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_full\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_components\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_svd_solver \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marpack\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrandomized\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_truncated(X, n_components, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_svd_solver)\n",
      "File \u001b[0;32m~/miniconda3/envs/robustbench/lib/python3.10/site-packages/sklearn/decomposition/_pca.py:548\u001b[0m, in \u001b[0;36mPCA._fit_full\u001b[0;34m(self, X, n_components)\u001b[0m\n\u001b[1;32m    538\u001b[0m X \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmean_\n\u001b[1;32m    540\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_array_api_compliant:\n\u001b[1;32m    541\u001b[0m     \u001b[38;5;66;03m# Use scipy.linalg with NumPy/SciPy inputs for the sake of not\u001b[39;00m\n\u001b[1;32m    542\u001b[0m     \u001b[38;5;66;03m# introducing unanticipated behavior changes. In the long run we\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    546\u001b[0m     \u001b[38;5;66;03m# solver by default though (assuming both are built against the\u001b[39;00m\n\u001b[1;32m    547\u001b[0m     \u001b[38;5;66;03m# same BLAS).\u001b[39;00m\n\u001b[0;32m--> 548\u001b[0m     U, S, Vt \u001b[38;5;241m=\u001b[39m \u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msvd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_matrices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    549\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    550\u001b[0m     U, S, Vt \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39msvd(X, full_matrices\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/robustbench/lib/python3.10/site-packages/scipy/linalg/_decomp_svd.py:127\u001b[0m, in \u001b[0;36msvd\u001b[0;34m(a, full_matrices, compute_uv, overwrite_a, check_finite, lapack_driver)\u001b[0m\n\u001b[1;32m    123\u001b[0m lwork \u001b[38;5;241m=\u001b[39m _compute_lwork(gesXd_lwork, a1\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], a1\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m    124\u001b[0m                        compute_uv\u001b[38;5;241m=\u001b[39mcompute_uv, full_matrices\u001b[38;5;241m=\u001b[39mfull_matrices)\n\u001b[1;32m    126\u001b[0m \u001b[38;5;66;03m# perform decomposition\u001b[39;00m\n\u001b[0;32m--> 127\u001b[0m u, s, v, info \u001b[38;5;241m=\u001b[39m \u001b[43mgesXd\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompute_uv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompute_uv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlwork\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlwork\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mfull_matrices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfull_matrices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverwrite_a\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverwrite_a\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m info \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LinAlgError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSVD did not converge\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for labels in label_to_plot:\n",
    "    init, img = [], []\n",
    "    for name, model in models.items():\n",
    "        print(name)\n",
    "\n",
    "        fix_seed(seed=seed)\n",
    "        x0, imgs = utils.new_samples(\n",
    "            model=model,\n",
    "            label=labels,\n",
    "            batch_size=num_samples,\n",
    "            step_size=0.8,\n",
    "            n_steps=20,\n",
    "            inizialization='pca',\n",
    "            n_steps_sampling=1,\n",
    "            loss=loss,\n",
    "            replay_buffer=replay_buffer,\n",
    "            buffer=buffer,\n",
    "            \n",
    "            variance = 0.95\n",
    "        )\n",
    "        init.append(x0)\n",
    "        img.append(imgs)\n",
    "\n",
    "    init_cat = torch.cat(init, dim=0)\n",
    "    img_cat = torch.cat(img, dim=0)\n",
    "\n",
    "    plot_imgs_generated(\n",
    "        init_cat,\n",
    "        inizialization=\"informative\",\n",
    "        rows= len(model_names_dict.keys()),\n",
    "        size=(32, 32),\n",
    "        path=\"./data/imgs_x0.pdf\",\n",
    "        name=\"imgs_x0: \",\n",
    "    )\n",
    "    plot_imgs_generated(\n",
    "        img_cat,\n",
    "        inizialization=\"informative\",\n",
    "        rows=len(model_names_dict.keys()),\n",
    "        size=(32, 32),\n",
    "        path=\"./data/imgs.pdf\",\n",
    "        name=\"imgs: \",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and n_steps = 50 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for labels in label_to_plot:\n",
    "    init, img = [], []\n",
    "    for name, model in models.items():\n",
    "        print(name)\n",
    "\n",
    "        fix_seed(seed=seed)\n",
    "        x0, imgs = utils.new_samples(\n",
    "            model=model,\n",
    "            label=labels,\n",
    "            batch_size=num_samples,\n",
    "            step_size=step_size,\n",
    "            n_steps=50,\n",
    "            inizialization='pca',\n",
    "            n_steps_sampling=1,\n",
    "            loss=loss,\n",
    "            replay_buffer=replay_buffer,\n",
    "            buffer=buffer,\n",
    "            \n",
    "            variance = 0.95\n",
    "        )\n",
    "        init.append(x0)\n",
    "        img.append(imgs)\n",
    "\n",
    "    init_cat = torch.cat(init, dim=0)\n",
    "    img_cat = torch.cat(img, dim=0)\n",
    "\n",
    "    utils_func.plot_imgs_generated(\n",
    "        init_cat,\n",
    "        inizialization=\"informative\",\n",
    "        rows= len(model_names_dict.keys()),\n",
    "        size=(40, 10),\n",
    "        path=\"./data/imgs_x0.pdf\",\n",
    "        name=\"imgs_x0: \",\n",
    "    )\n",
    "    utils_func.plot_imgs_generated(\n",
    "        img_cat,\n",
    "        inizialization=\"informative\",\n",
    "        rows=len(model_names_dict.keys()),\n",
    "        size=(40, 10),\n",
    "        path=\"./data/imgs.pdf\",\n",
    "        name=\"imgs: \",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "robustbench",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
