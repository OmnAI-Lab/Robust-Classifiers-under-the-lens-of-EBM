{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import enumeration\n",
    "import utils_func\n",
    "import argparse\n",
    "import torch\n",
    "import gc\n",
    "\n",
    "from torchvision.transforms import transforms\n",
    "\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "MODEL_NAMES_DICT = {\n",
    "    \"trades\": \"Zhang2019Theoretically\",\n",
    "    \"mart\": \"Wang2020Improving\",\n",
    "    \"wang2023\": \"Wang2023Better_WRN-28-10\",\n",
    "    'SAT' : 'Engstrom2019Robustness',\n",
    "    'wu2020' : 'Wu2020Adversarial',\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--threat model'], dest='threat model', nargs=None, const=None, default='Linf', type=<class 'str'>, choices=['Linf', 'L2'], required=False, help='threat model', metavar=None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parse arguments\n",
    "parser = argparse.ArgumentParser(description=\"Process some parameters.\")\n",
    "parser.add_argument(\"--wandb_logging\", type=bool, default=False, help=\"log to wandb\")\n",
    "parser.add_argument(\"--batch_size\", type=int, default=64, help=\"batch size\")\n",
    "parser.add_argument(\n",
    "    \"--dataset\",\n",
    "    type=str,\n",
    "    default=\"cifar10\",\n",
    "    choices=[\"cifar10\", \"cifar100\"],\n",
    "    help=\"dataset\",\n",
    ")\n",
    "parser.add_argument(\"--epsilon\", type=float, default=8 / 255, help=\"epsilon\")\n",
    "parser.add_argument(\"--alpha\", type=float, default=2 / 255, help=\"alpha\")\n",
    "parser.add_argument(\n",
    "    \"--sampling_iterations\", type=int, default=20, help=\"sampling iterations\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--architecture_name\", type=str, default=\"WideResNet\", help=\"architecture name\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--from_robustbench\", type=bool, default=True, help=\"load model from robustbench\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--init\",\n",
    "    type=str,\n",
    "    default=\"random\",\n",
    "    choices=[\"random\", \"pca\", \"gaussian\", \"informative\", \"informative+pca\"],\n",
    "    help=\"initialization for the generation\",\n",
    ")\n",
    "\n",
    "parser.add_argument(\"--seed\", type=int, default=0, help=\"random seed\")\n",
    "parser.add_argument(\"--data_dir\", type=str, default=\"./data\", help=\"data directory\")\n",
    "parser.add_argument(\n",
    "    \"--model_name\",\n",
    "    type=str,\n",
    "    default=\"Zhang2019Theoretically\",\n",
    "    choices=[MODEL_NAMES_DICT.keys()],\n",
    "    help=\"define the name of the model to be loaded\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--model_source\",\n",
    "    type=str,\n",
    "    default=\"robustbench\",\n",
    "    choices=[\"robustbench\", \"jem\", \"local\"],\n",
    "    help=\"the source from where the model is loaded\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--model_dir\",\n",
    "    type=str,\n",
    "    default=\"./models\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--threat model\",\n",
    "    type=str,\n",
    "    default=\"Linf\",\n",
    "    choices=[\"Linf\", \"L2\"],\n",
    "    help=\"threat model\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using default arguments\n"
     ]
    }
   ],
   "source": [
    "\n",
    "try:\n",
    "    args = parser.parse_args()\n",
    "    wandb = args.wandb_logging\n",
    "    batch_size = args.batch_size\n",
    "    dataset = args.dataset\n",
    "    epsilon = args.epsilon\n",
    "    alpha = args.alpha\n",
    "    sampling_iterations = args.sampling_iterations\n",
    "    architecture_name = args.architecture_name\n",
    "    from_robustbench = args.from_robustbench\n",
    "    initialization = args.init\n",
    "    data_dir = args.data_dir\n",
    "    seed = args.seed\n",
    "    model_name = args.model_name\n",
    "    model_source = args.model_source\n",
    "    model_dir = args.model_dir\n",
    "    threat_model = args.threat_model\n",
    "\n",
    "    print(\"Using arguments from parser\")\n",
    "\n",
    "except:\n",
    "    print(\"Using default arguments\")\n",
    "    wandb = False\n",
    "    batch_size = 64\n",
    "    dataset = \"cifar10\"\n",
    "    epsilon = 8 / 255\n",
    "    alpha = 2 / 255\n",
    "    sampling_iterations = 20\n",
    "    architecture_name = \"WideResNet\"\n",
    "    from_robustbench = True\n",
    "    init = \"random\"\n",
    "    data_dir = \"./data\"\n",
    "    seed = 0\n",
    "    model_name = \"Wang2020Improving\"\n",
    "    source = 'robustbench'\n",
    "    model_dir = \"./models\"\n",
    "    threat_model = \"Linf\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# threat model is {threath model}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import fix_seed\n",
    "\n",
    "fix_seed(seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "dataset_train, dataset_test = utils.load_clean_dataset(\n",
    "    dataset=enumeration.BenchmarkDataset(dataset.lower()),\n",
    "    n_examples=None,\n",
    "    data_dir=data_dir,\n",
    "    transform=transform,\n",
    ")\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    dataset_train, batch_size=batch_size, shuffle=True\n",
    ")\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    dataset_test, batch_size=batch_size, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define and load the model\n",
    "\n",
    "The default option is to load the model whose name is specified in the arguments "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from robustbench.utils import load_model\n",
    "from torch import nn\n",
    "\n",
    "from JEMPP.models.jem_models import F, CCF\n",
    "from JEMPP.models.wideresnet import Wide_ResNet as WideResNet\n",
    "\n",
    "\n",
    "ARCHITECTURE_DICT = {'wideresnet': WideResNet}\n",
    "\n",
    "assert architecture_name.lower() in ARCHITECTURE_DICT.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the model to load "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS = {}\n",
    "for m_name in MODEL_NAMES_DICT.keys():\n",
    "    MODELS[m_name] = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trades loaded\n",
      "Model mart loaded\n",
      "Model wang2023 loaded\n",
      "Model SAT loaded\n",
      "Model wu2020 loaded\n"
     ]
    }
   ],
   "source": [
    "for i, model_name_i in enumerate(MODEL_NAMES_DICT.keys()):\n",
    "    \n",
    "    if model_source == \"robustbench\":\n",
    "        model = load_model(\n",
    "            model_name=MODEL_NAMES_DICT[model_name_i],\n",
    "            dataset=dataset,\n",
    "            threat_model=threat_model,\n",
    "            model_dir=\"./models\",\n",
    "        )\n",
    "        model = nn.DataParallel(model, device_ids=[0])\n",
    "        model.to(device)\n",
    "    elif model_source == \"jem\":\n",
    "        model_cls = F\n",
    "        model = model_cls(\n",
    "            enumeration.dataset_image_size[dataset],\n",
    "            enumeration.dataset_num_classes[dataset],\n",
    "            norm=\"batch\",\n",
    "            n_classes=enumeration.dataset_num_classes[dataset],\n",
    "            model=\"wrn\",\n",
    "        )\n",
    "        ckpt_dict = torch.load(\"./models/cifar10/Linf/sadajem5_95.5_9.4.pt\")\n",
    "        model.load_state_dict(ckpt_dict[\"model_state_dict\"])\n",
    "        model = nn.DataParallel(model, device_ids=[0, 1])\n",
    "        model.to(device)\n",
    "        replay_buffer = ckpt_dict[\"replay_buffer\"]\n",
    "\n",
    "    elif model_source == \"local\":\n",
    "        model_path = model_dir + \"/wandb_model/\" + model_name + \".pt\"\n",
    "        # check missimg 2 factors in architecture instanciation\n",
    "        model = (\n",
    "            ARCHITECTURE_DICT[architecture_name]()\n",
    "            .to(device)\n",
    "            .load_state_dict(torch.load(model_path))\n",
    "            .eval()\n",
    "        )\n",
    "    \n",
    "    MODELS[model_name_i]=model.module\n",
    "    del model\n",
    "    print(f\"Model {model_name_i} loaded\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below there is the computation of the mean of the dataset for each category and then the estimate of the dataset as a GMM where each class is a gaussian distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Mean and Covariance Already Computed, skipping\n"
     ]
    }
   ],
   "source": [
    "utils_func.category_mean(\n",
    "    dload_train=train_dataloader,\n",
    "    n_classes=enumeration.dataset_num_classes[dataset],\n",
    "    name_dataset=dataset,\n",
    "    image_size=enumeration.dataset_image_size[dataset],\n",
    "    n_channels=3,\n",
    "    data_dir=data_dir,\n",
    ")\n",
    "BUFFER = utils.center_initialization(\n",
    "    dataset=dataset, n_classes=enumeration.dataset_num_classes[dataset]\n",
    ")\n",
    "\n",
    "REPLAY_BUFFER = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of the performance of the model for each initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The evaluation focuses on establishing the best way of initializing the generation.\n",
    "The fixed parameters are :\n",
    "- generated samples : 12 per class\n",
    "- labels to generate : a subset of 10 labels \n",
    "- seed: defined as argument \n",
    "- the norm considered in the perturbation: Linf \n",
    "- Loss for the perturbation : energy_xy\n",
    "- Dataset\n",
    "- optimizer: SGLD vs Heun\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 5\n",
    "label_to_plot = [i for i in range(10)]\n",
    "label_to_plot = [[i for i in label_to_plot[:len(label_to_plot) // 2]], [i for i in label_to_plot[len(label_to_plot) // 2:]]]\n",
    "#print(label_to_plot)\n",
    "loss = 'reference_energy_xy'\n",
    "sgld = 'SGLD'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## the init is `pca`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "PLOT of THE PCA INIT\n",
      "SAT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mary/miniconda3/envs/robustbench/lib/python3.10/site-packages/torch/nn/modules/conv.py:456: UserWarning: Applied workaround for CuDNN issue, install nvrtc.so (Triggered internally at /opt/conda/conda-bld/pytorch_1695392020201/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:80.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "cuDNN error: CUDNN_STATUS_NOT_INITIALIZED",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(name)\n\u001b[1;32m     22\u001b[0m fix_seed(seed\u001b[38;5;241m=\u001b[39mseed)\n\u001b[0;32m---> 23\u001b[0m x0, imgs, energy \u001b[38;5;241m=\u001b[39m \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnew_samples\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNUM_SAMPLES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstep_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mN_STEPS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43minizialization\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpca\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_steps_sampling\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43malgo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msgld\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreplay_buffer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mREPLAY_BUFFER\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBUFFER\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvariance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.95\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnoise_variance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompute_energy_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m init\u001b[38;5;241m.\u001b[39mappend(x0)\n\u001b[1;32m     42\u001b[0m img\u001b[38;5;241m.\u001b[39mappend(imgs)\n",
      "File \u001b[0;32m/media/mary/T7/code/LE_PGD/ablation/utils.py:760\u001b[0m, in \u001b[0;36mnew_samples\u001b[0;34m(model, label, batch_size, step_size, n_steps, inizialization, n_steps_sampling, loss, algo, replay_buffer, buffer, dataset, **kwargs)\u001b[0m\n\u001b[1;32m    758\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_steps_sampling):\n\u001b[1;32m    759\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m algo \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSGLD\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 760\u001b[0m         x0, final_samples, energy_dict \u001b[38;5;241m=\u001b[39m \u001b[43msample_q_SGLD\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    761\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    762\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreplay_buffer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreplay_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    763\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    764\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstep_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstep_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    765\u001b[0m \u001b[43m            \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    766\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    767\u001b[0m \u001b[43m            \u001b[49m\u001b[43minizialization\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minizialization\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    768\u001b[0m \u001b[43m            \u001b[49m\u001b[43mloss_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    769\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    770\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbuffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    771\u001b[0m \u001b[43m            \u001b[49m\u001b[43menergy_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menergy_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    772\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    773\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    774\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m algo \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHeun\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    775\u001b[0m         x0, final_samples \u001b[38;5;241m=\u001b[39m sample_q_Heun(\n\u001b[1;32m    776\u001b[0m             model,\n\u001b[1;32m    777\u001b[0m             replay_buffer\u001b[38;5;241m=\u001b[39mreplay_buffer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    787\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    788\u001b[0m         )\n",
      "File \u001b[0;32m/media/mary/T7/code/LE_PGD/ablation/utils.py:670\u001b[0m, in \u001b[0;36msample_q_SGLD\u001b[0;34m(model, replay_buffer, batch_size, step_size, y, n_steps, inizialization, loss_func, sigma_pca, mean_img, N_components, retained_variance, more_variance, dataset, buffer, energy_dict, **kwargs)\u001b[0m\n\u001b[1;32m    666\u001b[0m samples\u001b[38;5;241m.\u001b[39mrequires_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    668\u001b[0m y, loss \u001b[38;5;241m=\u001b[39m compute_loss(y, loss_func, model(samples))\n\u001b[0;32m--> 670\u001b[0m grad \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m    672\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    674\u001b[0m velocity \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;241m-\u001b[39mstep_size \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m grad\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m momentum \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    677\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m momentum \u001b[38;5;241m*\u001b[39m velocity \u001b[38;5;241m-\u001b[39m step_size \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m grad\n\u001b[1;32m    678\u001b[0m )\n\u001b[1;32m    680\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m HM:\n",
      "File \u001b[0;32m~/miniconda3/envs/robustbench/lib/python3.10/site-packages/torch/autograd/__init__.py:394\u001b[0m, in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched, materialize_grads)\u001b[0m\n\u001b[1;32m    390\u001b[0m     result \u001b[38;5;241m=\u001b[39m _vmap_internals\u001b[38;5;241m.\u001b[39m_vmap(vjp, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, allow_none_pass_through\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)(\n\u001b[1;32m    391\u001b[0m         grad_outputs_\n\u001b[1;32m    392\u001b[0m     )\n\u001b[1;32m    393\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 394\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    395\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    396\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_outputs_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    398\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    400\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_unused\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    401\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    402\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    403\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m materialize_grads:\n\u001b[1;32m    404\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\n\u001b[1;32m    405\u001b[0m         output\n\u001b[1;32m    406\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m output \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    407\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mzeros_like(\u001b[38;5;28minput\u001b[39m, requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    408\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m (output, \u001b[38;5;28minput\u001b[39m) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(result, t_inputs)\n\u001b[1;32m    409\u001b[0m     )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED"
     ]
    }
   ],
   "source": [
    "NUM_SAMPLES = \n",
    "LABEL_TO_PLOT = list(range(1))\n",
    "#LABEL_TO_PLOT = [LABEL_TO_PLOT[:len(LABEL_TO_PLOT) // 2], LABEL_TO_PLOT[len(LABEL_TO_PLOT) // 2:]]\n",
    "print(LABEL_TO_PLOT)\n",
    "N_STEPS = 50\n",
    "\n",
    "\n",
    "\n",
    "num_classes = 10\n",
    "pca_ENERGY_DICT_xy_dist = {\n",
    "    f\"{i}_{j}\": [] for j in range(num_classes) for i in range(num_classes)\n",
    "}\n",
    "size_plots = 20\n",
    "\n",
    "print(\"PLOT of THE PCA INIT\")\n",
    "\n",
    "for labels in LABEL_TO_PLOT:\n",
    "    init, img = [], []\n",
    "    for name, model in MODELS.items():\n",
    "        print(name)\n",
    "\n",
    "        fix_seed(seed=seed)\n",
    "        x0, imgs, energy = utils.new_samples(\n",
    "            model=model,\n",
    "            label=labels,\n",
    "            batch_size=NUM_SAMPLES,\n",
    "            step_size=0.5,\n",
    "            n_steps=N_STEPS,\n",
    "            inizialization=\"pca\",\n",
    "            n_steps_sampling=1,\n",
    "            algo=sgld,\n",
    "            loss=loss,\n",
    "            replay_buffer=REPLAY_BUFFER,\n",
    "            buffer=BUFFER,\n",
    "            \n",
    "            alpha=1,\n",
    "            variance=0.95,\n",
    "            noise_variance=0.001,\n",
    "            compute_energy_model=True,\n",
    "        )\n",
    "        init.append(x0)\n",
    "        img.append(imgs)\n",
    "\n",
    "    init_cat = torch.cat(init, dim=0)\n",
    "\n",
    "    img_cat = torch.cat(img, dim=0)\n",
    "\n",
    "    utils_func.plot_imgs_generated(\n",
    "        img_cat,\n",
    "        inizialization=\"init: pca, loss: energy_xy, No HM, No momentum\",\n",
    "        rows=len(MODEL_NAMES_DICT.keys()),\n",
    "        size=(size_plots, size_plots),\n",
    "        path=\"./data/imgs.pdf\",\n",
    "        name=\"imgs: \",\n",
    "    )\n",
    "    for key, value in energy.items():\n",
    "        if len(value) > 0:\n",
    "            pca_ENERGY_DICT_xy_dist[key] = value\n",
    "\n",
    "\n",
    "pca_ENERGY_DICT={\n",
    "    f\"{i}_{j}\": [] for j in range(num_classes) for i in range(num_classes)\n",
    "}\n",
    "for key, value in pca_ENERGY_DICT_xy_dist.items():\n",
    "    for sample in range(NUM_SAMPLES):\n",
    "        flag_list = [value[i+sample] for i in range(0, len(value), NUM_SAMPLES)]\n",
    "        pca_ENERGY_DICT[key].append(flag_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "robustbench",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
