{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Notebook: Different Attacks Induce Diverse Energy Landscapes\n",
        "\n",
        "Corresponding to the section \"Different Attacks Induce Diverse Energy Landscapes\" of the paper: \"*Shedding More Light on Robust Classifiers under the Lens of Energy-based Model.* \"\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "eE9GxW4vy9tV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import necessary libraries and initialize settings\n"
      ],
      "metadata": {
        "id": "kAMa78Y32P7_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tWuAq8xVvTfL"
      },
      "outputs": [],
      "source": [
        "import torch, gc\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "import torchvision.datasets as datasets\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from robustbench.utils import load_model\n",
        "from torch import nn\n",
        "import random\n",
        "from robustbench.utils import load_model\n",
        "import torchattacks\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "\n",
        "\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "torch.manual_seed(0)\n",
        "np.random.seed(0)\n",
        "random.seed(0)\n",
        "\n",
        "\n",
        "\n",
        "wandb_log=True\n",
        "#attack_details\n",
        "config={\n",
        "# attack details\n",
        "\"dataset\": \"CIFAR-10\",\n",
        "\"attack_type\" : \"PGD\",\n",
        "\"epsilon\" : 8/255,\n",
        "\"targeted\": True,\n",
        "\"alpha\" : 2/255,\n",
        "\"gamma\" : 0,\n",
        "\"steps\": 2,\n",
        "# adv_Model_deatils\n",
        "\"model_name\":'Standard',\n",
        "\"from_RobustBench\":True,\n",
        "\"dataset_trained_on\" : 'CIFAR-10',\n",
        "\"target_label\": 'random',\n",
        "\"kappa\": 0,\n",
        "\"batch_size\": 256\n",
        "}\n",
        "\n",
        "if wandb_log==True:\n",
        "    import wandb\n",
        "    wandb.init(\n",
        "    # set the wandb project where this run will be logged\n",
        "        project=\"<project_name>\",\n",
        "        save_code=True,\n",
        "        config=config,\n",
        "        entity=\"robustgen\"\n",
        "    )\n",
        "    dataset=wandb.config['dataset']\n",
        "    attack_type=wandb.config['attack_type']\n",
        "    targeted=wandb.config['targeted']\n",
        "    epsilon=wandb.config['epsilon']\n",
        "    alpha=wandb.config['alpha']\n",
        "    factor=wandb.config['gamma']\n",
        "    steps=wandb.config['steps']\n",
        "    model_name = wandb.config['model_name']\n",
        "    from_RobustBench = wandb.config['from_RobustBench']\n",
        "    dataset_trained_on = wandb.config['dataset_trained_on']\n",
        "    target_label = wandb.config['target_label']\n",
        "    kappa = wandb.config['kappa']\n",
        "    batch_size=wandb.config['batch_size']\n",
        "\n",
        "    current_run_name = wandb.run.name\n",
        "    print(current_run_name)\n",
        "else:\n",
        "    dataset=config['dataset']\n",
        "    attack_type=config['attack_type']\n",
        "    epsilon=config['epsilon']\n",
        "    alpha=config['alpha']\n",
        "    factor=config['gamma']\n",
        "    steps=config['steps']\n",
        "    targeted=config['targeted']\n",
        "    model_name = config['model_name']\n",
        "    from_RobustBench = config['from_RobustBench']\n",
        "    dataset_trained_on = config['dataset_trained_on']\n",
        "    target_label = config['target_label']\n",
        "    kappa = config['kappa']\n",
        "    batch_size=config['batch_size']\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f'Using device: {device}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utility functions\n"
      ],
      "metadata": {
        "id": "ujn4O5bP5_r1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get accuracy of the model on original data (test set)\n",
        "def test_model(model, test_dataloader):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for img, labels in test_dataloader:\n",
        "            img = img.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(img)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f'Test Accuracy: {accuracy:.2f}%')\n",
        "    return accuracy\n",
        "\n",
        "# Get accuracy of the model on adversarial data (test set)\n",
        "def measure_accuracy(model, test_dataloader, epsilon, alpha, steps):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    # Define the PGD attack\n",
        "    attack = torchattacks.PGD(model, eps=epsilon, alpha=alpha, steps=steps)\n",
        "\n",
        "    for images, labels in test_dataloader:\n",
        "\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Perturb the images using the PGD attack\n",
        "        perturbed_images = attack(images, labels)\n",
        "\n",
        "        outputs = model(perturbed_images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f'Robust Accuracy: {accuracy:.2f}%')\n",
        "    return accuracy\n",
        "\n",
        "# Compute the energy as the negative logarithm of the sum of the exponentials of the logits\n",
        "def compute_energy(logits):\n",
        "    energy = -torch.logsumexp(logits, dim=1)\n",
        "    return energy\n",
        "\n",
        "# Compute joint energy wrt ground truth label\n",
        "def compute_energy_xy(logits, labels):\n",
        "    # Get the logit corresponding to the correct label\n",
        "    correct_logits = logits[torch.arange(logits.size(0)), labels]\n",
        "    energy = - correct_logits\n",
        "    return energy\n",
        "\n",
        "# Compute energy vectors for real data\n",
        "def compute_energy_vector(model, test_dataloader):\n",
        "    model.eval()\n",
        "    energy_vector = []\n",
        "    energy_vector_xy = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_dataloader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            logits = model(images)\n",
        "            energy = compute_energy(logits)\n",
        "            energy_xy = compute_energy_xy(logits, labels)\n",
        "\n",
        "            energy_vector.extend(energy.cpu().numpy())\n",
        "            energy_vector_xy.extend(energy_xy.cpu().numpy())\n",
        "\n",
        "    return np.array(energy_vector), np.array(energy_vector_xy)\n",
        "\n",
        "\n",
        "def compute_attack(model, test_dataloader, eps=8/255, alpha=2/255, steps=10, targeted=False, attack=attack_type):\n",
        "    \"\"\"return the energy vector of the test set after attack.\n",
        "    Args:\n",
        "        model (_type_): Pytorch model\n",
        "        test_dataloader (_type_): dataloader of the test set\n",
        "        epsilon (float): maximum perturbation of adversaries\n",
        "        alpha (float): step size of PGD attack\n",
        "        steps (int): number of steps of PGD attack\n",
        "        targeted: False if the attack is untargeted\n",
        "        device: device cuda\n",
        "\n",
        "    Returns:\n",
        "        _type_: energy vector of the test set\n",
        "    \"\"\"\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    energy_vector = []\n",
        "    energy_vector_xy = []\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    if attack == 'PGD':\n",
        "        attack = torchattacks.PGD(model, eps=eps, alpha=alpha, steps=steps)\n",
        "\n",
        "    elif attack == 'TRADES-PGD':\n",
        "        attack = torchattacks.TPGD(model, eps=eps, alpha=alpha, steps=steps)\n",
        "\n",
        "    elif attack == 'APGD-T':\n",
        "        attack = torchattacks.APGDT(model, norm='Linf', eps=eps, steps=steps, n_restarts=1, seed=0, verbose=False, n_classes=10)\n",
        "\n",
        "    elif attack == 'APGD':\n",
        "        attack = torchattacks.APGD(model, norm='Linf', eps=eps, steps=steps, n_restarts=1, seed=0, loss='ce', verbose=False)\n",
        "\n",
        "    elif attack == 'APGD-DLR':\n",
        "        attack = torchattacks.APGD(model, norm='Linf', eps=eps, steps=steps, n_restarts=1, seed=0, loss='dlr', verbose=False)\n",
        "\n",
        "    elif attack == 'FAB':\n",
        "        attack = torchattacks.FAB(model, norm='Linf', steps=steps, eps=8/255, n_restarts=1, verbose=True, multi_targeted=False, n_classes=10)\n",
        "\n",
        "    elif attack == 'Square':\n",
        "        attack = torchattacks.Square(model, norm='Linf', eps=8/255, n_queries=1000, n_restarts=1, seed=0, verbose=False, loss='margin')\n",
        "\n",
        "    elif attack == 'CW':\n",
        "        attack = torchattacks.CW(model, c=1, kappa=kappa, steps=steps, lr=0.01)\n",
        "        if targeted:\n",
        "            print('targeted attack CW')\n",
        "            if target_label=='random':\n",
        "                print('targeted attack CW')\n",
        "                attack.targeted=True\n",
        "                attack.set_mode_targeted_random()\n",
        "            elif target_label=='least':\n",
        "                print('targeted attack CW')\n",
        "                attack.targeted=True\n",
        "                attack.get_least_likely_label()\n",
        "\n",
        "\n",
        "    for images, labels in test_dataloader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Perturb the images using the PGD attack\n",
        "        perturbed_images = attack(images, labels)\n",
        "\n",
        "        logits = model(perturbed_images)\n",
        "\n",
        "        _, predicted = torch.max(logits.data, 1)\n",
        "\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "        energy = compute_energy(logits)\n",
        "        energy_xy = compute_energy_xy(logits, labels)\n",
        "\n",
        "        energy_vector.extend(energy.detach().cpu().numpy())\n",
        "        energy_vector_xy.extend(energy_xy.detach().cpu().numpy())\n",
        "\n",
        "\n",
        "    if wandb_log==True:\n",
        "        wandb.log({\n",
        "               \"robust accuracy top1\": 100*correct/total\n",
        "               })\n",
        "\n",
        "    return np.array(energy_vector), np.array(energy_vector_xy)\n",
        "\n",
        "\n",
        "# Plot the histogram of clean and adversarial energies computed\n",
        "def plot_energy(clean_energy, adversarial_energy, bins=100, name=\"energy\", name_model=model_name+'_'+attack_type):\n",
        "\n",
        "    x = np.stack((clean_energy, adversarial_energy),axis=1)\n",
        "    fig, ax = plt.subplots(figsize =(7, 5))\n",
        "\n",
        "    ax.set_ylim(0,700)\n",
        "\n",
        "    ax.set_xlim(-45,20)\n",
        "\n",
        "    ax.hist(x, bins=np.linspace(-50,20,bins), histtype='bar' , color=['lightblue','red'], label=[\"clean data\", 'adversarial data'], stacked=False )\n",
        "\n",
        "    if name==\"energy\":\n",
        "        ax.set_xlabel('E(x)', fontsize=27)\n",
        "    else:\n",
        "        ax.set_xlabel('E(x,y)', fontsize=27)\n",
        "\n",
        "    ax.set_ylabel('# samples',  fontsize=27)\n",
        "    plt.legend(loc='upper left', fontsize=20)\n",
        "    fig.set_size_inches(8, 6)\n",
        "    plt.tick_params(axis='x', labelsize=18)\n",
        "    plt.tick_params(axis='y', labelsize=18)\n",
        "\n",
        "    # Show the plot\n",
        "    plt.savefig(name_model +'_'+ name +'.pdf', bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "xYKDU43zwYbV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load test data and model\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4NFPlHDR9UsO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the transforms\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# Load CIFAR-10 test dataset\n",
        "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "\n",
        "# Create the dataloaders\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=10, pin_memory=True)\n",
        "\n",
        "#importing from robust bench\n",
        "if from_RobustBench:\n",
        "    model = load_model(model_name=model_name, dataset='cifar10', threat_model=\"Linf\", model_dir=\"robustness2/models\")\n",
        "\n",
        "    model = nn.DataParallel(model, device_ids=[0, 1])\n",
        "    model.to(device)\n",
        "\n",
        "#using local model\n",
        "else:\n",
        "    model_path='/home/robustgen/Downloads/PhD/notebooks/models/wandb_model/'+ model_name +'.pt'\n",
        "    model = WideResNet().to(device)\n",
        "    model.load_state_dict(torch.load(model_path))\n",
        "    model.eval()\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ftrMPhi1wRBL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calculate accuracies, energy vectors on clean and adversarial data"
      ],
      "metadata": {
        "id": "Id3p-i6U9nFo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "top1 = test_model(model, test_dataloader)\n",
        "if wandb_log==True:\n",
        "    wandb.log({\"clean accuracy top 1\": top1,\n",
        "               })\n",
        "\n",
        "v_e, v_exy = compute_energy_vector(model, test_dataloader)\n",
        "v_adv_e, v_adv_exy = compute_attack(model, test_dataloader, attack=attack_type, steps=steps, targeted=targeted)"
      ],
      "metadata": {
        "id": "Dc5Co0ZXyoYM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot Marginal Energy i.e. E(x) for clean and adversarial data"
      ],
      "metadata": {
        "id": "TTJJCqoF97DN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_energy(v_e, v_adv_e, bins=200)"
      ],
      "metadata": {
        "id": "Unlx-XFEykxt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot Joint Energy wrt to ground truth label y, i.e. E(x,y) for clean and adversarial data"
      ],
      "metadata": {
        "id": "UWpyWiwQ-N3a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_energy(v_exy, v_adv_exy, bins=200, name=\"<enter_name>\")"
      ],
      "metadata": {
        "id": "hYhUPlJ3yjmf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save energies if needed (optional)"
      ],
      "metadata": {
        "id": "yLSiKr5w-_7L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists('./data_vector'):\n",
        "    os.makedirs('./data_vector')\n",
        "\n",
        "\n",
        "# Save the energy vectors as npy files\n",
        "np.save(\"./data_vector/clean_energy.npy\", v_e)\n",
        "np.save(\"./data_vector/adversarial_energy.npy\", v_adv_e)\n",
        "np.save(\"./data_vector/clean_energy_xy.npy\", v_exy)\n",
        "np.save(\"./data_vector/adversarial_energy_xy.npy\", v_adv_exy)\n",
        "# Log the vectors into wandb\n",
        "if wandb_log == True:\n",
        "    wandb.save(\"./data_vector/clean_energy.npy\")\n",
        "    wandb.save(\"./data_vector/adversarial_energy.npy\")\n",
        "    wandb.save(\"./data_vector/clean_energy_xy.npy\")\n",
        "    wandb.save(\"./data_vector/adversarial_energy_xy.npy\")\n",
        "\n",
        "if wandb_log==True:\n",
        "    wandb.finish()\n"
      ],
      "metadata": {
        "id": "cq25Lk_YwSId"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}